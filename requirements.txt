# === CORE (voice, TTS, VAD, transcription) ===
openai-whisper
faster-whisper
ctranslate2
sentencepiece
edge-tts
webrtcvad
pyttsx3
pyaudio
speechrecognition
sounddevice
numpy
scipy

# === COMPUTER VISION ===
Pillow
opencv-python
torch
torchvision
torchaudio

# === SYSTEM AUTOMATION AND CONTROL ===
keyboard
pyautogui
pyperclip
psutil

# === WEB SCRAPING + SEARCH ===
requests
beautifulsoup4
aiohttp

# === DATABASE ===
sqlite-utils

# === GRAPHICAL USER INTERFACE (GUI) ===
tk

# === EMOTIONAL ANALYSIS (voice or written reflection) ===
pyAudioAnalysis
matplotlib
scikit-learn

# === UTILITIES ===
regex
tqdm
python-dotenv
pywin32     # Windows compatibility
unidecode

# === DEVELOPMENT TOOLS ===
jsbeautifier

# === LLMs, RAG & EMBEDDINGS ===
# llama-index==0.10.40
# llama-index-embeddings-ollama
# ollama-py  # Client for Ollama local API

# === TESTS ===
pytest

# === EXTRA: MULTILINGUAL & FORMATTING ===
langdetect
langid
chardet

# === EXTERNAL DEPENDENCIES (not via pip) ===
# Ollama (for LLaMA 3.3, Vision 90B and Embedding Models)
# CUDA Toolkit (for GPU acceleration)
# ffmpeg (audio/video processing)
# git / git-lfs (for models, optional)

# ===============================
# See README for manual steps!
